{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from utility import calculate_input_gradients, perturb_inputs, preprocess_images, \\\n",
    "                    postprocess_features, save_data_hdf5,get_dataset_hdf5,\\\n",
    "                    build_one_class_svm, combine_inliners_outliers, apply_temp_scale_to_model,\\\n",
    "                    apply_log_temp_scale_to_model, perturb_inputs_odin, extract_layer_features\n",
    " \n",
    "from utility_db_outliers import load_dataset\n",
    "from models_lib import load_custom_model_for_ds\n",
    "import h5py\n",
    "# from metrics2 import *\n",
    "from metrics import *\n",
    "from general_setting import *\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "#------------\n",
    "from utility_methods import *\n",
    "# from utility_methods2 import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import scipy.io as sio\n",
    "import tensorflow.keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Lambda\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, MaxPooling2D, UpSampling2D, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 VGG\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "SAVE_RESULTS = True\n",
    "id_name=ID_DS_LIST[1] # selects the ID dataset.\n",
    "id_model=ID_MODEL_LIST[1]  # select the deep model used for training ID dataset.\n",
    "print(id_name,id_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing was done for  CIFAR10 VGG\n",
      "Preprocessing was done for  CIFAR10 VGG\n"
     ]
    }
   ],
   "source": [
    "(org_traing_data, org_training_labels),(id_eva_data,org_testing_labels)  = load_dataset(id_name)\n",
    "\n",
    "org_traing_data_processed = preprocess_images(id_name, org_traing_data, id_model, verbose=True)\n",
    "id_eva_data_processed = preprocess_images(id_name, id_eva_data, id_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = org_traing_data_processed\n",
    "y_train = org_training_labels\n",
    "x_test = id_eva_data_processed\n",
    "y_test = org_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler( )\n",
    "scaler.fit(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test_0 = scaler.transform(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test = x_test_0.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],x_test.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(x_train.flatten().reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]*x_train.shape[3]))\n",
    "x_train_0 = scaler.transform(x_train.flatten().reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]*x_train.shape[3]))\n",
    "x_train = x_train_0.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],x_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数\n",
    "input_shape = (32, 32, 3)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "# filters = 16  \n",
    "latent_dim = 1024 # 隐变量取2维只是为了方便后面画图\n",
    "epochs = 100\n",
    "x_in = Input(shape=input_shape)\n",
    "x = x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2D(filters=filters,\n",
    "                kernel_size=kernel_size,\n",
    "                activation='relu',\n",
    "                strides=2,\n",
    "                padding='same')(x)\n",
    "    # elif filters == \"max\":\n",
    "    #     x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    # elif filters == \"average\":\n",
    "    #     x = AveragePooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# 备份当前shape，等下构建decoder的时候要用\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(4*4*128, activation='relu')(x)\n",
    "# 算p(Z|X)的均值和方差\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# 重参数技巧\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重参数层，相当于给输入加入噪声\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# 解码层，也就是生成器部分\n",
    "# 先搭建为一个独立的模型，然后再调用模型\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same')(x)\n",
    "    # elif filters == \"max\" or filters == \"average\":\n",
    "    #             x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "outputs = Conv2DTranspose(filters=3,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='sigmoid',\n",
    "                        padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建为一个独立的模型\n",
    "encoder = Model(x_in, z_mean)\n",
    "\n",
    "decoder = Model(latent_inputs, outputs)\n",
    "\n",
    "x_out = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "vae = Model(x_in, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"model_1\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_1\".\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 64)     18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73856       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4196352     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         2098176     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1024)         0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 32, 3)    2231907     lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,717,859\n",
      "Trainable params: 10,717,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# xent_loss是重构loss，kl_loss是KL loss\n",
    "xent_loss = K.sum(K.binary_crossentropy(x_in, x_out), axis=[1, 2, 3])\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "# add_loss是新增的方法，用于更灵活地添加各种loss\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 2048.8856 - val_loss: 1968.1406\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1968.0286 - val_loss: 1952.7644\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1948.6853 - val_loss: 1951.3068\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1935.3231 - val_loss: 1958.6573\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1929.2501 - val_loss: 1917.8004\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1923.1278 - val_loss: 1928.8299\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1915.2705 - val_loss: 1924.8960\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1908.4289 - val_loss: 1923.2063\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1904.3934 - val_loss: 1909.7127\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1901.0665 - val_loss: 1904.2859\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1899.0079 - val_loss: 1892.2732\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1896.0163 - val_loss: 1896.4592\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1893.0710 - val_loss: 1898.7423\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1889.5773 - val_loss: 1895.9471\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1885.2414 - val_loss: 1898.2654\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1880.4370 - val_loss: 1877.4947\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1876.2412 - val_loss: 1882.9291\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1872.8297 - val_loss: 1876.7889\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1868.9401 - val_loss: 1872.1864\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1865.5404 - val_loss: 1869.2461\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1862.7232 - val_loss: 1865.2610\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1860.4030 - val_loss: 1862.4397\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1858.0608 - val_loss: 1867.2815\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1856.1834 - val_loss: 1863.3237\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1854.6079 - val_loss: 1858.3661\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1852.8111 - val_loss: 1855.1493\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1851.2098 - val_loss: 1852.5032\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1849.7618 - val_loss: 1851.1519\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1848.4438 - val_loss: 1852.7049\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1847.2913 - val_loss: 1855.2087\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1846.6963 - val_loss: 1847.2472\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1845.7636 - val_loss: 1857.9645\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1845.1883 - val_loss: 1847.4892\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1844.4954 - val_loss: 1845.7645\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1843.8547 - val_loss: 1849.1840\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1843.1334 - val_loss: 1847.4338\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1842.4683 - val_loss: 1846.2607\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1841.9286 - val_loss: 1845.7990\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1841.3461 - val_loss: 1848.1521\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1840.7535 - val_loss: 1846.5092\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1840.1997 - val_loss: 1844.8349\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1839.6669 - val_loss: 1845.9341\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1839.2596 - val_loss: 1844.6185\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1839.0050 - val_loss: 1844.1928\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1838.5727 - val_loss: 1842.0459\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1838.3192 - val_loss: 1843.9115\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1838.0562 - val_loss: 1844.6392\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1837.8996 - val_loss: 1843.0184\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1837.5321 - val_loss: 1847.3294\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1837.3714 - val_loss: 1844.2179\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1837.1311 - val_loss: 1845.5721\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1836.8790 - val_loss: 1841.5530\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1836.6769 - val_loss: 1848.0175\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1836.3902 - val_loss: 1839.1381\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1836.1624 - val_loss: 1840.9801\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1835.7840 - val_loss: 1840.3459\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1835.6322 - val_loss: 1842.7525\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1835.2937 - val_loss: 1837.3433\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1834.8788 - val_loss: 1838.4841\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1834.7525 - val_loss: 1840.6310\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1834.4736 - val_loss: 1835.7753\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1834.2226 - val_loss: 1836.6325\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1834.0546 - val_loss: 1840.0838\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1833.8552 - val_loss: 1836.7350\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1833.7258 - val_loss: 1835.7274\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1833.3508 - val_loss: 1839.7851\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1833.2213 - val_loss: 1834.6199\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1832.9244 - val_loss: 1840.9332\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1832.9172 - val_loss: 1836.6357\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1832.6592 - val_loss: 1835.4668\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1832.4877 - val_loss: 1834.9738\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1832.2757 - val_loss: 1834.4770\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1832.0351 - val_loss: 1837.8672\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1831.8317 - val_loss: 1836.0275\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1831.6538 - val_loss: 1840.7714\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1831.4695 - val_loss: 1834.4348\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1831.2667 - val_loss: 1835.4572\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1831.0873 - val_loss: 1836.4151\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1830.8931 - val_loss: 1836.1144\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1830.6625 - val_loss: 1832.4469\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1830.5955 - val_loss: 1834.1634\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1830.3790 - val_loss: 1833.4667\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1830.1788 - val_loss: 1833.5943\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1830.1020 - val_loss: 1833.0989\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1829.9007 - val_loss: 1833.4227\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1829.7122 - val_loss: 1834.8335\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1829.7242 - val_loss: 1831.2084\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1829.5789 - val_loss: 1833.3214\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1829.3543 - val_loss: 1833.2363\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1829.3302 - val_loss: 1833.2296\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1829.2739 - val_loss: 1830.3406\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1829.0318 - val_loss: 1833.7995\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1829.1589 - val_loss: 1831.7657\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1828.9310 - val_loss: 1831.6072\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1828.7747 - val_loss: 1839.3446\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1828.7015 - val_loss: 1835.2248\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1828.6868 - val_loss: 1835.5979\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1828.5050 - val_loss: 1834.8970\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1828.3301 - val_loss: 1833.6581\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1828.2254 - val_loss: 1833.0399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd0e7b8c88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save('./vae_models/%s_%s.h5'%(id_name,id_model))\n",
    "vae.save_weights('./vae_models/%s_%s_weights.h5'%(id_name,id_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(x_1, x_2):\n",
    "    diff = np.abs(x_1 - x_2)\n",
    "    marks = np.mean(np.power(diff, 2), axis=(1,2,3))\n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9347, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load('./advs_new/%s_%s_normal.npy'%(id_name, id_model),allow_pickle=True)\n",
    "scaler.fit(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test_0 = scaler.transform(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test = x_test_0.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],x_test.shape[3])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_id = []\n",
    "for i in range(len(x_test)):\n",
    "    x_test_encoded = encoder.predict(x_test[i].reshape(1,32,32,3))\n",
    "    xx = decoder.predict(x_test_encoded)\n",
    "    score = mark(x_test[i],xx)\n",
    "    # print(score)\n",
    "    sc_id.append(-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_inliners_outliers(inliers, outliers, i_label=1, o_label=0, verbose=False):\n",
    "\n",
    "    temp_outliers = outliers\n",
    "    temp_inliers  = inliers\n",
    "    if i_label==1:\n",
    "        i_labels = np.ones(temp_inliers.shape[0])\n",
    "    else:\n",
    "        i_labels = np.zeros(temp_inliers.shape[0])\n",
    "        \n",
    "    if o_label==0:\n",
    "        o_labels = np.zeros(temp_outliers.shape[0])\n",
    "    else:\n",
    "        o_labels = np.ones(temp_outliers.shape[0])       \n",
    "              \n",
    "    mixed_labels =  np.append(i_labels, o_labels)\n",
    "    mixed_data = np.vstack((temp_inliers, temp_outliers))\n",
    "\n",
    "    return mixed_data, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of fgsm:\n",
      "\n",
      "tnr_at_95_tpr: 76.73107890410937\n",
      "detection_acc: 85.86553945157968\n",
      "AUROC:  99.78140797797927\n",
      "\n",
      "\n",
      "The results of bim-a:\n",
      "\n",
      "tnr_at_95_tpr: 4.9114331722462445\n",
      "detection_acc: 49.95571658564812\n",
      "AUROC:  54.26831266465353\n",
      "\n",
      "\n",
      "The results of bim-b:\n",
      "\n",
      "tnr_at_95_tpr: 4.267310789000836\n",
      "detection_acc: 49.63365539402541\n",
      "AUROC:  54.32845820640287\n",
      "\n",
      "\n",
      "The results of jsma:\n",
      "\n",
      "tnr_at_95_tpr: 5.981136415850228\n",
      "detection_acc: 50.4905682074501\n",
      "AUROC:  54.10272957424633\n",
      "\n",
      "\n",
      "The results of cw-l2:\n",
      "\n",
      "tnr_at_95_tpr: 64.35472739746544\n",
      "detection_acc: 79.67736369825771\n",
      "AUROC:  91.78609481362568\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = np.asarray(sc_id)\n",
    "ADV_DS_LIST = (\"fgsm\", \"bim-a\", \"bim-b\", \"jsma\", \"cw-l2\")\n",
    "for i, ds_name in enumerate(ADV_DS_LIST):\n",
    "    adv = id_name+\"_\"+id_model+\"_\"+ ds_name\n",
    "    das = np.load('./advs_new/'+adv+'.npy',allow_pickle=True)\n",
    "    \n",
    "    scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "    \n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,32,32,3))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood)\n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood)\n",
    " \n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "    #     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ds_name))\n",
    "    #     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "    #     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_inx specifies the index of the OODL found by \"find_oodl\" jupyter file.\n",
    "REM_TOP_LAYER = -2\n",
    "NUM_CLASS = 10\n",
    "if id_name==\"MNIST\" and id_model==\"LeNet\":\n",
    "    layer_inx = 0\n",
    "    OOD_DS_LIST       = OOD_DS_LIST_MNIST\n",
    "    #**********************************************************\n",
    "elif id_name==\"CIFAR10\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_CIFAR10\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 20\n",
    "    #**********************************************************\n",
    "elif id_name==\"SVHN\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_SVHN\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of TINYIMAGENET_RESIZED_32:\n",
      "\n",
      "tnr_at_95_tpr: 49.8599999995014\n",
      "detection_acc: 72.4299999992757\n",
      "AUROC:  83.165592\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of LSUN_RESIZED:\n",
      "\n",
      "tnr_at_95_tpr: 65.4399999993456\n",
      "detection_acc: 80.2199999991978\n",
      "AUROC:  90.900345\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of ISUN_PATCHED:\n",
      "\n",
      "tnr_at_95_tpr: 53.38935574169872\n",
      "detection_acc: 74.19467787037435\n",
      "AUROC:  84.80936582633055\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of SVHN_CROPPED:\n",
      "\n",
      "tnr_at_95_tpr: 1.1216963736896064\n",
      "detection_acc: 48.060848186369796\n",
      "AUROC:  13.46894783343577\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of G_255:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of U_255:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vriance模块(OODL大类别 --> 删除同样的feature maps)\n",
    "test = np.asarray(sc_id)\n",
    "for i, ood_ds_name in enumerate(OOD_DS_LIST):\n",
    "    (_,_),(ood_eva_data,_) = load_dataset(ood_ds_name)\n",
    "    das = preprocess_images(id_name, ood_eva_data, id_model, verbose=True)\n",
    "    \n",
    "    scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "    \n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,32,32,3))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood) \n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "#     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ood_ds_name))\n",
    "#     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "#     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of foolingimages:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  99.99299799999999\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ood_ds_name = 'foolingimages'\n",
    "\n",
    "das = np.load('adv_datasets/%s_%s_fooling_images.npy'%(id_name,id_model))\n",
    "\n",
    "scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "\n",
    "sc_ood = []\n",
    "for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,32,32,3))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "\n",
    "ood = np.asarray(sc_ood) \n",
    "scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "# print('scores is:', (scores[10000:20000]))\n",
    "fpr, tpr = nums(scores, mixed_labels)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lens = id_eva_data_processed.shape[0]\n",
    "FP,TN,TP,FN = ErrorRateAt95Recall1(lens,scores, mixed_labels)\n",
    "ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "print('The results of %s:\\n' %(ood_ds_name))\n",
    "# print(get_summary_statistics(scores, mixed_labels))\n",
    "# print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "# print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "print(\"AUROC: \",ROC*100)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b5abb0188ba9781ac08b493d925deea1ef4eb1a2330813f3a395ce70cb798d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
