{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from utility import calculate_input_gradients, perturb_inputs, preprocess_images, \\\n",
    "                    postprocess_features, save_data_hdf5,get_dataset_hdf5,\\\n",
    "                    build_one_class_svm, combine_inliners_outliers, apply_temp_scale_to_model,\\\n",
    "                    apply_log_temp_scale_to_model, perturb_inputs_odin, extract_layer_features\n",
    " \n",
    "from utility_db_outliers import load_dataset\n",
    "from models_lib import load_custom_model_for_ds\n",
    "import h5py\n",
    "# from metrics2 import *\n",
    "from metrics import *\n",
    "from general_setting import *\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "#------------\n",
    "from utility_methods import *\n",
    "# from utility_methods2 import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import scipy.io as sio\n",
    "import tensorflow.keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Lambda\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, MaxPooling2D, UpSampling2D, AveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST LeNet\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "SAVE_RESULTS = True\n",
    "id_name=ID_DS_LIST[0] # selects the ID dataset.\n",
    "id_model=ID_MODEL_LIST[0]  # select the deep model used for training ID dataset.\n",
    "print(id_name,id_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing is not needed.\n",
      "Preprocessing is not needed.\n"
     ]
    }
   ],
   "source": [
    "(org_traing_data, org_training_labels),(id_eva_data,org_testing_labels)  = load_dataset(id_name)\n",
    "\n",
    "org_traing_data_processed = preprocess_images(id_name, org_traing_data, id_model, verbose=True)\n",
    "id_eva_data_processed = preprocess_images(id_name, id_eva_data, id_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = org_traing_data_processed\n",
    "y_train = org_training_labels\n",
    "x_test = id_eva_data_processed\n",
    "y_test = org_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "# structure = [16, \"average\", 32]\n",
    "structure = [16, 32]\n",
    "latent_dim = 784 # 隐变量取2维只是为了方便后面画图\n",
    "epochs = 50\n",
    "x_in = Input(shape=input_shape)\n",
    "x = x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2D(filters=filters,\n",
    "                kernel_size=kernel_size,\n",
    "                activation='relu',\n",
    "                strides=2,\n",
    "                padding='same')(x)\n",
    "    # elif filters == \"max\":\n",
    "    #     x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    # elif filters == \"average\":\n",
    "    #     x = AveragePooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# 备份当前shape，等下构建decoder的时候要用\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(7*7*32, activation='relu')(x)\n",
    "# 算p(Z|X)的均值和方差\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# 重参数技巧\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重参数层，相当于给输入加入噪声\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# 解码层，也就是生成器部分\n",
    "# 先搭建为一个独立的模型，然后再调用模型\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same')(x)\n",
    "    # elif filters == \"max\" or filters == \"average\":\n",
    "    #     x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "outputs = Conv2DTranspose(filters=1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='sigmoid',\n",
    "                        padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建为一个独立的模型\n",
    "encoder = Model(x_in, z_mean)\n",
    "\n",
    "decoder = Model(latent_inputs, outputs)\n",
    "\n",
    "x_out = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "vae = Model(x_in, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"model_4\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_4\".\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 16)   160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 32)     4640        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1568)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1568)         2460192     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 784)          1230096     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 784)          1230096     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 784)          0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 28, 28, 1)    1240433     lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,165,617\n",
      "Trainable params: 6,165,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# xent_loss是重构loss，kl_loss是KL loss\n",
    "xent_loss = K.sum(K.binary_crossentropy(x_in, x_out), axis=[1, 2, 3])\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "# add_loss是新增的方法，用于更灵活地添加各种loss\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 196.6807 - val_loss: 163.3486\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 157.9738 - val_loss: 151.0958\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 148.1202 - val_loss: 145.4120\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 142.6992 - val_loss: 142.1653\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 139.5781 - val_loss: 137.3011\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 136.7510 - val_loss: 135.9183\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 133.7257 - val_loss: 130.9712\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 130.5361 - val_loss: 130.7719\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 127.6336 - val_loss: 126.4794\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 124.6219 - val_loss: 122.2084\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 121.8539 - val_loss: 119.7481\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 119.6230 - val_loss: 119.4591\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 117.8754 - val_loss: 115.7342\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 116.0900 - val_loss: 115.3184\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 114.7162 - val_loss: 114.1345\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 113.3026 - val_loss: 113.6929\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 112.2084 - val_loss: 112.2984\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 111.2913 - val_loss: 110.5654\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 110.3907 - val_loss: 108.9763\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 109.5808 - val_loss: 108.7522\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 108.8740 - val_loss: 108.6435\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 108.2062 - val_loss: 107.3773\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 107.7729 - val_loss: 106.4315\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 107.2038 - val_loss: 106.8269\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 106.8321 - val_loss: 106.6755\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 106.4845 - val_loss: 106.1476\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 106.0846 - val_loss: 105.3011\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 105.8056 - val_loss: 104.9573\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 105.4365 - val_loss: 104.8543\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 105.1368 - val_loss: 105.1909\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 104.9275 - val_loss: 104.9492\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 104.6363 - val_loss: 103.8649\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 104.4515 - val_loss: 103.9752\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 104.2029 - val_loss: 103.5312\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 103.9990 - val_loss: 103.6457\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 103.7958 - val_loss: 103.8222\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 103.6213 - val_loss: 102.8687\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 103.4143 - val_loss: 103.5114\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 103.2527 - val_loss: 103.2826\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 103.1020 - val_loss: 102.3654\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 103.0008 - val_loss: 102.8147\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.8204 - val_loss: 103.4450\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.7473 - val_loss: 102.7927\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 102.6303 - val_loss: 102.4573\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.4906 - val_loss: 102.4618\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.3658 - val_loss: 101.9942\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.2551 - val_loss: 102.3855\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.1639 - val_loss: 101.6701\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 102.0012 - val_loss: 102.5126\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 101.9731 - val_loss: 101.3549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ec562d2e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save('./vae_models/%s_%s.h5'%(id_name,id_model))\n",
    "vae.save_weights('./vae_models/%s_%s_weights.h5'%(id_name,id_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = vae.load_weights('./vae_models/%s_%s_weights.h5'%(id_name,id_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(x_1, x_2):\n",
    "    diff = np.abs(x_1 - x_2)\n",
    "    marks = np.mean(np.power(diff, 2), axis=(1,2,3))\n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9920, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load('./advs_new/%s_%s_normal.npy'%(id_name, id_model),allow_pickle=True)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_id = []\n",
    "for i in range(len(x_test)):\n",
    "    x_test_encoded = encoder.predict(x_test[i].reshape(1,28,28,1))\n",
    "    xx = decoder.predict(x_test_encoded)\n",
    "    score = mark(x_test[i],xx)\n",
    "    # print(score)\n",
    "    sc_id.append(-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_inliners_outliers(inliers, outliers, i_label=1, o_label=0, verbose=False):\n",
    "\n",
    "    temp_outliers = outliers\n",
    "    temp_inliers  = inliers\n",
    "    if i_label==1:\n",
    "        i_labels = np.ones(temp_inliers.shape[0])\n",
    "    else:\n",
    "        i_labels = np.zeros(temp_inliers.shape[0])\n",
    "        \n",
    "    if o_label==0:\n",
    "        o_labels = np.zeros(temp_outliers.shape[0])\n",
    "    else:\n",
    "        o_labels = np.ones(temp_outliers.shape[0])       \n",
    "              \n",
    "    mixed_labels =  np.append(i_labels, o_labels)\n",
    "    mixed_data = np.vstack((temp_inliers, temp_outliers))\n",
    "\n",
    "    return mixed_data, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of fgsm:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999898374\n",
      "detection_acc: 97.49999999901686\n",
      "AUROC:  100.0\n",
      "\n",
      "\n",
      "The results of bim-a:\n",
      "\n",
      "tnr_at_95_tpr: 30.873983739523638\n",
      "detection_acc: 62.93699186928681\n",
      "AUROC:  82.53240338026795\n",
      "\n",
      "\n",
      "The results of bim-b:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999898374\n",
      "detection_acc: 97.49999999901686\n",
      "AUROC:  99.99077194166233\n",
      "\n",
      "\n",
      "The results of jsma:\n",
      "\n",
      "tnr_at_95_tpr: 93.37398373888847\n",
      "detection_acc: 94.18699186896923\n",
      "AUROC:  98.80308292956556\n",
      "\n",
      "\n",
      "The results of cw-l2:\n",
      "\n",
      "tnr_at_95_tpr: 9.156504064947596\n",
      "detection_acc: 52.078252031998794\n",
      "AUROC:  65.19119386543964\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = np.asarray(sc_id)\n",
    "ADV_DS_LIST = (\"fgsm\", \"bim-a\", \"bim-b\", \"jsma\", \"cw-l2\")\n",
    "for i, ds_name in enumerate(ADV_DS_LIST):\n",
    "    adv = id_name+\"_\"+id_model+\"_\"+ ds_name\n",
    "    das = np.load('./advs_new/'+adv+'.npy',allow_pickle=True)\n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,28,28,1))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood)\n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood)\n",
    " \n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "    #     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ds_name))\n",
    "    #     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "    #     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_inx specifies the index of the OODL found by \"find_oodl\" jupyter file.\n",
    "REM_TOP_LAYER = -2\n",
    "NUM_CLASS = 10\n",
    "if id_name==\"MNIST\" and id_model==\"LeNet\":\n",
    "    layer_inx = 0\n",
    "    OOD_DS_LIST       = OOD_DS_LIST_MNIST\n",
    "    #**********************************************************\n",
    "elif id_name==\"CIFAR10\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_CIFAR10\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 20\n",
    "    #**********************************************************\n",
    "elif id_name==\"SVHN\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_SVHN\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing is not needed.\n",
      "The results of FASHION_MNIST:\n",
      "\n",
      "tnr_at_95_tpr: 99.63999999900359\n",
      "detection_acc: 97.31999999902679\n",
      "AUROC:  99.88759499999999\n",
      "\n",
      "\n",
      "Preprocessing is not needed.\n",
      "The results of OMNIGLOT_RESIZED_28:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n",
      "Preprocessing is not needed.\n",
      "The results of MNIST_GAUSSIAN_NOISE_ODIN:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n",
      "Preprocessing is not needed.\n",
      "The results of MNIST_UNIFORM_NOISE:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  99.99999999999999\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vriance模块(OODL大类别 --> 删除同样的feature maps)\n",
    "test = np.asarray(sc_id)\n",
    "for i, ood_ds_name in enumerate(OOD_DS_LIST):\n",
    "    (_,_),(ood_eva_data,_) = load_dataset(ood_ds_name)\n",
    "    das = preprocess_images(id_name, ood_eva_data, id_model, verbose=True)\n",
    "    \n",
    "    # scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    # das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    # das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "    \n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,28,28,1))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood) \n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "#     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ood_ds_name))\n",
    "#     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "#     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of foolingimages:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ood_ds_name = 'foolingimages'\n",
    "\n",
    "das = np.load('adv_datasets/%s_%s_fooling_images.npy'%(id_name,id_model))\n",
    "\n",
    "# scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "# das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "# das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "\n",
    "sc_ood = []\n",
    "for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,28,28,1))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "\n",
    "ood = np.asarray(sc_ood) \n",
    "scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "# print('scores is:', (scores[10000:20000]))\n",
    "fpr, tpr = nums(scores, mixed_labels)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lens = id_eva_data_processed.shape[0]\n",
    "FP,TN,TP,FN = ErrorRateAt95Recall1(lens,scores, mixed_labels)\n",
    "ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "print('The results of %s:\\n' %(ood_ds_name))\n",
    "# print(get_summary_statistics(scores, mixed_labels))\n",
    "# print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "# print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "print(\"AUROC: \",ROC*100)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b5abb0188ba9781ac08b493d925deea1ef4eb1a2330813f3a395ce70cb798d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
