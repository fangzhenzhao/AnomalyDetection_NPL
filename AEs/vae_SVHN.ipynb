{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/zhaofz/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from utility import calculate_input_gradients, perturb_inputs, preprocess_images, \\\n",
    "                    postprocess_features, save_data_hdf5,get_dataset_hdf5,\\\n",
    "                    build_one_class_svm, combine_inliners_outliers, apply_temp_scale_to_model,\\\n",
    "                    apply_log_temp_scale_to_model, perturb_inputs_odin, extract_layer_features\n",
    " \n",
    "from utility_db_outliers import load_dataset\n",
    "from models_lib import load_custom_model_for_ds\n",
    "import h5py\n",
    "# from metrics2 import *\n",
    "from metrics import *\n",
    "from general_setting import *\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "#------------\n",
    "from utility_methods import *\n",
    "# from utility_methods2 import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import scipy.io as sio\n",
    "import tensorflow.keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Lambda\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, MaxPooling2D, UpSampling2D, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVHN ResNet\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "SAVE_RESULTS = True\n",
    "id_name=ID_DS_LIST[2] # selects the ID dataset.\n",
    "id_model=ID_MODEL_LIST[2]  # select the deep model used for training ID dataset.\n",
    "print(id_name,id_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing was done for  SVHN ResNet\n",
      "Preprocessing was done for  SVHN ResNet\n"
     ]
    }
   ],
   "source": [
    "(org_traing_data, org_training_labels),(id_eva_data,org_testing_labels)  = load_dataset(id_name)\n",
    "\n",
    "org_traing_data_processed = preprocess_images(id_name, org_traing_data, id_model, verbose=True)\n",
    "id_eva_data_processed = preprocess_images(id_name, id_eva_data, id_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = org_traing_data_processed\n",
    "y_train = org_training_labels\n",
    "x_test = id_eva_data_processed\n",
    "y_test = org_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数\n",
    "input_shape = (32, 32, 3)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "# filters = 16  \n",
    "latent_dim = 1024 # 隐变量取2维只是为了方便后面画图\n",
    "epochs = 100\n",
    "x_in = Input(shape=input_shape)\n",
    "x = x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2D(filters=filters,\n",
    "                kernel_size=kernel_size,\n",
    "                activation='relu',\n",
    "                strides=2,\n",
    "                padding='same')(x)\n",
    "    # elif filters == \"max\":\n",
    "    #     x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    # elif filters == \"average\":\n",
    "    #     x = AveragePooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# 备份当前shape，等下构建decoder的时候要用\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(4*4*128, activation='relu')(x)\n",
    "# 算p(Z|X)的均值和方差\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# 重参数技巧\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重参数层，相当于给输入加入噪声\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# 解码层，也就是生成器部分\n",
    "# 先搭建为一个独立的模型，然后再调用模型\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same')(x)\n",
    "    # elif filters == \"max\" or filters == \"average\":\n",
    "    #             x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "outputs = Conv2DTranspose(filters=3,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='sigmoid',\n",
    "                        padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建为一个独立的模型\n",
    "encoder = Model(x_in, z_mean)\n",
    "\n",
    "decoder = Model(latent_inputs, outputs)\n",
    "\n",
    "x_out = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "vae = Model(x_in, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"model_1\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"model_1\".\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 64)     18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    73856       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4196352     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         2098176     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1024)         0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 32, 32, 3)    2231907     lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,717,859\n",
      "Trainable params: 10,717,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# xent_loss是重构loss，kl_loss是KL loss\n",
    "xent_loss = K.sum(K.binary_crossentropy(x_in, x_out), axis=[1, 2, 3])\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "# add_loss是新增的方法，用于更灵活地添加各种loss\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/100\n",
      "73257/73257 [==============================] - 13s 178us/step - loss: 2040.1249 - val_loss: 1926.9146\n",
      "Epoch 2/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1987.2287 - val_loss: 1928.0178\n",
      "Epoch 3/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1975.8592 - val_loss: 1930.3512\n",
      "Epoch 4/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1967.7676 - val_loss: 1898.4895\n",
      "Epoch 5/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1963.4664 - val_loss: 1917.2232\n",
      "Epoch 6/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1959.8447 - val_loss: 1902.4656\n",
      "Epoch 7/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1956.9241 - val_loss: 1891.2253\n",
      "Epoch 8/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1954.3282 - val_loss: 1906.8575\n",
      "Epoch 9/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1952.3717 - val_loss: 1884.0916\n",
      "Epoch 10/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1949.9735 - val_loss: 1896.5890\n",
      "Epoch 11/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1948.2079 - val_loss: 1884.8576\n",
      "Epoch 12/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1945.5552 - val_loss: 1883.4550\n",
      "Epoch 13/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1943.3815 - val_loss: 1876.2289\n",
      "Epoch 14/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1941.6088 - val_loss: 1878.5811\n",
      "Epoch 15/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1940.2367 - val_loss: 1871.4059\n",
      "Epoch 16/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1938.5043 - val_loss: 1871.0403\n",
      "Epoch 17/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1936.2217 - val_loss: 1867.9491\n",
      "Epoch 18/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1934.4192 - val_loss: 1867.4117\n",
      "Epoch 19/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1932.6377 - val_loss: 1866.7357\n",
      "Epoch 20/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1930.8670 - val_loss: 1864.4782\n",
      "Epoch 21/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1929.5759 - val_loss: 1861.8673\n",
      "Epoch 22/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1928.4905 - val_loss: 1857.6305\n",
      "Epoch 23/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1927.1756 - val_loss: 1858.5586\n",
      "Epoch 24/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1926.1303 - val_loss: 1859.4252\n",
      "Epoch 25/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1925.3703 - val_loss: 1858.0397\n",
      "Epoch 26/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1924.8418 - val_loss: 1857.7797\n",
      "Epoch 27/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1924.3119 - val_loss: 1859.6263\n",
      "Epoch 28/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1923.8644 - val_loss: 1855.1726\n",
      "Epoch 29/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1923.3738 - val_loss: 1856.7634\n",
      "Epoch 30/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1922.8114 - val_loss: 1855.0135\n",
      "Epoch 31/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1922.4232 - val_loss: 1854.9483\n",
      "Epoch 32/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1921.9713 - val_loss: 1854.0986\n",
      "Epoch 33/100\n",
      "73257/73257 [==============================] - 10s 140us/step - loss: 1921.5516 - val_loss: 1856.6887\n",
      "Epoch 34/100\n",
      "73257/73257 [==============================] - 10s 140us/step - loss: 1921.1655 - val_loss: 1851.3004\n",
      "Epoch 35/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1920.5859 - val_loss: 1851.7411\n",
      "Epoch 36/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1920.0745 - val_loss: 1852.5424\n",
      "Epoch 37/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1919.4961 - val_loss: 1851.9419\n",
      "Epoch 38/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1918.8261 - val_loss: 1847.2519\n",
      "Epoch 39/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1918.2725 - val_loss: 1848.1148\n",
      "Epoch 40/100\n",
      "73257/73257 [==============================] - 10s 140us/step - loss: 1917.8234 - val_loss: 1847.6658\n",
      "Epoch 41/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1917.4550 - val_loss: 1847.1960\n",
      "Epoch 42/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1917.1509 - val_loss: 1850.0287\n",
      "Epoch 43/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1916.9530 - val_loss: 1848.8049\n",
      "Epoch 44/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1916.7120 - val_loss: 1845.9240\n",
      "Epoch 45/100\n",
      "73257/73257 [==============================] - 11s 145us/step - loss: 1916.4998 - val_loss: 1844.8058\n",
      "Epoch 46/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1916.2957 - val_loss: 1848.0786\n",
      "Epoch 47/100\n",
      "73257/73257 [==============================] - 11s 146us/step - loss: 1916.1646 - val_loss: 1846.1918\n",
      "Epoch 48/100\n",
      "73257/73257 [==============================] - 11s 146us/step - loss: 1916.0197 - val_loss: 1848.2136\n",
      "Epoch 49/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.8008 - val_loss: 1847.6550\n",
      "Epoch 50/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.6606 - val_loss: 1848.6369\n",
      "Epoch 51/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.6077 - val_loss: 1849.4030\n",
      "Epoch 52/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.4391 - val_loss: 1846.8905\n",
      "Epoch 53/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.3993 - val_loss: 1844.4449\n",
      "Epoch 54/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.2743 - val_loss: 1844.2440\n",
      "Epoch 55/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1915.1644 - val_loss: 1847.3956\n",
      "Epoch 56/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1915.0789 - val_loss: 1847.5841\n",
      "Epoch 57/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1914.9747 - val_loss: 1844.7230\n",
      "Epoch 58/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1914.8953 - val_loss: 1844.6286\n",
      "Epoch 59/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1914.8211 - val_loss: 1844.9937\n",
      "Epoch 60/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1914.6640 - val_loss: 1849.6424\n",
      "Epoch 61/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1914.6279 - val_loss: 1848.0907\n",
      "Epoch 62/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1914.5285 - val_loss: 1842.0667\n",
      "Epoch 63/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1914.4657 - val_loss: 1849.5345\n",
      "Epoch 64/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1914.3701 - val_loss: 1842.7360\n",
      "Epoch 65/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1914.3426 - val_loss: 1843.6962\n",
      "Epoch 66/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1914.2620 - val_loss: 1843.9198\n",
      "Epoch 67/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1914.1926 - val_loss: 1843.8361\n",
      "Epoch 68/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1914.1612 - val_loss: 1845.6419\n",
      "Epoch 69/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1914.0640 - val_loss: 1843.3256\n",
      "Epoch 70/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1914.0169 - val_loss: 1846.9129\n",
      "Epoch 71/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.9282 - val_loss: 1842.7792\n",
      "Epoch 72/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.9050 - val_loss: 1842.1106\n",
      "Epoch 73/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.7691 - val_loss: 1843.5425\n",
      "Epoch 74/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.7847 - val_loss: 1846.6824\n",
      "Epoch 75/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.7071 - val_loss: 1842.1000\n",
      "Epoch 76/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.6374 - val_loss: 1842.6768\n",
      "Epoch 77/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1913.6125 - val_loss: 1842.3937\n",
      "Epoch 78/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1913.4701 - val_loss: 1844.9642\n",
      "Epoch 79/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1913.5151 - val_loss: 1845.0485\n",
      "Epoch 80/100\n",
      "73257/73257 [==============================] - 10s 143us/step - loss: 1913.4536 - val_loss: 1841.5662\n",
      "Epoch 81/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1913.3432 - val_loss: 1840.8501\n",
      "Epoch 82/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1913.2533 - val_loss: 1842.9432\n",
      "Epoch 83/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1913.1979 - val_loss: 1842.8498\n",
      "Epoch 84/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1913.0945 - val_loss: 1842.3526\n",
      "Epoch 85/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1913.0305 - val_loss: 1842.1593\n",
      "Epoch 86/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1912.9723 - val_loss: 1842.7515\n",
      "Epoch 87/100\n",
      "73257/73257 [==============================] - 11s 145us/step - loss: 1912.8986 - val_loss: 1844.0739\n",
      "Epoch 88/100\n",
      "73257/73257 [==============================] - 11s 144us/step - loss: 1912.8664 - val_loss: 1842.7699\n",
      "Epoch 89/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.8144 - val_loss: 1841.0734\n",
      "Epoch 90/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.7414 - val_loss: 1847.2052\n",
      "Epoch 91/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.7386 - val_loss: 1842.0060\n",
      "Epoch 92/100\n",
      "73257/73257 [==============================] - 10s 141us/step - loss: 1912.6419 - val_loss: 1842.0258\n",
      "Epoch 93/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.6352 - val_loss: 1841.0304\n",
      "Epoch 94/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.5650 - val_loss: 1844.2721\n",
      "Epoch 95/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.4968 - val_loss: 1841.9124\n",
      "Epoch 96/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.4430 - val_loss: 1841.0419\n",
      "Epoch 97/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.4077 - val_loss: 1848.5000\n",
      "Epoch 98/100\n",
      "73257/73257 [==============================] - 10s 140us/step - loss: 1912.3141 - val_loss: 1841.8531\n",
      "Epoch 99/100\n",
      "73257/73257 [==============================] - 10s 139us/step - loss: 1912.3028 - val_loss: 1845.1651\n",
      "Epoch 100/100\n",
      "73257/73257 [==============================] - 10s 142us/step - loss: 1912.2624 - val_loss: 1840.9030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc6d96cdd68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save('./vae_models/%s_%s.h5'%(id_name,id_model))\n",
    "vae.save_weights('./vae_models/%s_%s_weights.h5'%(id_name,id_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(x_1, x_2):\n",
    "    diff = np.abs(x_1 - x_2)\n",
    "    marks = np.mean(np.power(diff, 2), axis=(1,2,3))\n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25022, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load('./advs_new/%s_%s_normal.npy'%(id_name, id_model),allow_pickle=True)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_id = []\n",
    "for i in range(len(x_test)):\n",
    "    x_test_encoded = encoder.predict(x_test[i].reshape(1,32,32,3))\n",
    "    xx = decoder.predict(x_test_encoded)\n",
    "    score = mark(x_test[i],xx)\n",
    "    # print(score)\n",
    "    sc_id.append(-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_inliners_outliers(inliers, outliers, i_label=1, o_label=0, verbose=False):\n",
    "\n",
    "    temp_outliers = outliers\n",
    "    temp_inliers  = inliers\n",
    "    if i_label==1:\n",
    "        i_labels = np.ones(temp_inliers.shape[0])\n",
    "    else:\n",
    "        i_labels = np.zeros(temp_inliers.shape[0])\n",
    "        \n",
    "    if o_label==0:\n",
    "        o_labels = np.zeros(temp_outliers.shape[0])\n",
    "    else:\n",
    "        o_labels = np.ones(temp_outliers.shape[0])       \n",
    "              \n",
    "    mixed_labels =  np.append(i_labels, o_labels)\n",
    "    mixed_data = np.vstack((temp_inliers, temp_outliers))\n",
    "\n",
    "    return mixed_data, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of fgsm:\n",
      "\n",
      "tnr_at_95_tpr: 91.2502082288387\n",
      "detection_acc: 93.12433582904941\n",
      "AUROC:  99.01038856248512\n",
      "\n",
      "\n",
      "The results of bim-a:\n",
      "\n",
      "tnr_at_95_tpr: 5.289022155566846\n",
      "detection_acc: 50.14374279241349\n",
      "AUROC:  52.80341693522792\n",
      "\n",
      "\n",
      "The results of bim-b:\n",
      "\n",
      "tnr_at_95_tpr: 15.900383141696233\n",
      "detection_acc: 55.4494232854782\n",
      "AUROC:  86.33904042789399\n",
      "\n",
      "\n",
      "The results of jsma:\n",
      "\n",
      "tnr_at_95_tpr: 16.73330001658865\n",
      "detection_acc: 55.86588172292441\n",
      "AUROC:  77.22924983396116\n",
      "\n",
      "\n",
      "The results of cw-l2:\n",
      "\n",
      "tnr_at_95_tpr: 4.955855405609879\n",
      "detection_acc: 49.97715941743501\n",
      "AUROC:  50.16825965271096\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = np.asarray(sc_id)\n",
    "ADV_DS_LIST = (\"fgsm\", \"bim-a\", \"bim-b\", \"jsma\", \"cw-l2\")\n",
    "for i, ds_name in enumerate(ADV_DS_LIST):\n",
    "    adv = id_name+\"_\"+id_model+\"_\"+ ds_name\n",
    "    das = np.load('./advs_new/'+adv+'.npy',allow_pickle=True)\n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,32,32,3))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood)\n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood)\n",
    " \n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "    #     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ds_name))\n",
    "    #     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "    #     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_inx specifies the index of the OODL found by \"find_oodl\" jupyter file.\n",
    "REM_TOP_LAYER = -2\n",
    "NUM_CLASS = 10\n",
    "if id_name==\"MNIST\" and id_model==\"LeNet\":\n",
    "    layer_inx = 0\n",
    "    OOD_DS_LIST       = OOD_DS_LIST_MNIST\n",
    "    #**********************************************************\n",
    "elif id_name==\"CIFAR10\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_CIFAR10\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 20\n",
    "    #**********************************************************\n",
    "elif id_name==\"SVHN\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_SVHN\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing was done for  SVHN ResNet\n",
      "The results of TINYIMAGENET_RESIZED_32:\n",
      "\n",
      "tnr_at_95_tpr: 94.86999999905129\n",
      "detection_acc: 94.93423171415571\n",
      "AUROC:  98.82915507836509\n",
      "\n",
      "\n",
      "Preprocessing was done for  SVHN ResNet\n",
      "The results of LSUN_RESIZED:\n",
      "\n",
      "tnr_at_95_tpr: 98.499999999015\n",
      "detection_acc: 96.74923171413758\n",
      "AUROC:  99.51437346342964\n",
      "\n",
      "\n",
      "Preprocessing was done for  SVHN ResNet\n",
      "The results of ISUN_PATCHED:\n",
      "\n",
      "tnr_at_95_tpr: 96.16806722581323\n",
      "detection_acc: 95.5832653275367\n",
      "AUROC:  99.10810009314113\n",
      "\n",
      "\n",
      "Preprocessing was done for  SVHN ResNet\n",
      "The results of CIFAR10:\n",
      "\n",
      "tnr_at_95_tpr: 80.17999999919819\n",
      "detection_acc: 87.58923171422917\n",
      "AUROC:  96.19687768899816\n",
      "\n",
      "\n",
      "Preprocessing was done for  SVHN ResNet\n",
      "The results of G_255:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.49923171413006\n",
      "AUROC:  100.0\n",
      "\n",
      "\n",
      "Preprocessing was done for  SVHN ResNet\n",
      "The results of U_255:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.49923171413006\n",
      "AUROC:  100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vriance模块(OODL大类别 --> 删除同样的feature maps)\n",
    "test = np.asarray(sc_id)\n",
    "for i, ood_ds_name in enumerate(OOD_DS_LIST):\n",
    "    (_,_),(ood_eva_data,_) = load_dataset(ood_ds_name)\n",
    "    das = preprocess_images(id_name, ood_eva_data, id_model, verbose=True)\n",
    "    \n",
    "    # scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    # das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    # das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "    \n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,32,32,3))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood) \n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "#     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ood_ds_name))\n",
    "#     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "#     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of foolingimages:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.49923171413006\n",
      "AUROC:  100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ood_ds_name = 'foolingimages'\n",
    "\n",
    "das = np.load('adv_datasets/%s_%s_fooling_images.npy'%(id_name,id_model))\n",
    "\n",
    "# scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "# das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "# das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "\n",
    "sc_ood = []\n",
    "for i in range(len(das)):\n",
    "        x_test_encoded = encoder.predict(das[i].reshape(1,32,32,3))\n",
    "        xx = decoder.predict(x_test_encoded)\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "\n",
    "ood = np.asarray(sc_ood) \n",
    "scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "# print('scores is:', (scores[10000:20000]))\n",
    "fpr, tpr = nums(scores, mixed_labels)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lens = id_eva_data_processed.shape[0]\n",
    "FP,TN,TP,FN = ErrorRateAt95Recall1(lens,scores, mixed_labels)\n",
    "ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "print('The results of %s:\\n' %(ood_ds_name))\n",
    "# print(get_summary_statistics(scores, mixed_labels))\n",
    "# print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "# print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "print(\"AUROC: \",ROC*100)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b5abb0188ba9781ac08b493d925deea1ef4eb1a2330813f3a395ce70cb798d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
