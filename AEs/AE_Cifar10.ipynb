{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from utility import calculate_input_gradients, perturb_inputs, preprocess_images, \\\n",
    "                    postprocess_features, save_data_hdf5,get_dataset_hdf5,\\\n",
    "                    build_one_class_svm, combine_inliners_outliers, apply_temp_scale_to_model,\\\n",
    "                    apply_log_temp_scale_to_model, perturb_inputs_odin, extract_layer_features\n",
    " \n",
    "from utility_db_outliers import load_dataset\n",
    "from models_lib import load_custom_model_for_ds\n",
    "import h5py\n",
    "# from metrics2 import *\n",
    "from metrics import *\n",
    "from general_setting import *\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "#------------\n",
    "from utility_methods import *\n",
    "# from utility_methods2 import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import scipy.io as sio\n",
    "import tensorflow.keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Lambda\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, MaxPooling2D, UpSampling2D, AveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 VGG\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "SAVE_RESULTS = True\n",
    "id_name=ID_DS_LIST[1] # selects the ID dataset.\n",
    "id_model=ID_MODEL_LIST[1]  # select the deep model used for training ID dataset.\n",
    "print(id_name,id_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing was done for  CIFAR10 VGG\n",
      "Preprocessing was done for  CIFAR10 VGG\n"
     ]
    }
   ],
   "source": [
    "(org_traing_data, org_training_labels),(id_eva_data,org_testing_labels)  = load_dataset(id_name)\n",
    "\n",
    "org_traing_data_processed = preprocess_images(id_name, org_traing_data, id_model, verbose=True)\n",
    "id_eva_data_processed = preprocess_images(id_name, id_eva_data, id_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = org_traing_data_processed\n",
    "y_train = org_training_labels\n",
    "x_test = id_eva_data_processed\n",
    "y_test = org_testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler( )\n",
    "scaler.fit(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test_0 = scaler.transform(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test = x_test_0.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],x_test.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(x_train.flatten().reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]*x_train.shape[3]))\n",
    "x_train_0 = scaler.transform(x_train.flatten().reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2]*x_train.shape[3]))\n",
    "x_train = x_train_0.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],x_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络参数\n",
    "input_shape = (32, 32, 3)\n",
    "batch_size = 256\n",
    "kernel_size = 3\n",
    "# filters = 16  \n",
    "latent_dim = 1024 # 隐变量取2维只是为了方便后面画图\n",
    "epochs = 100\n",
    "x_in = Input(shape=input_shape)\n",
    "x = x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2D(filters=filters,\n",
    "                kernel_size=kernel_size,\n",
    "                activation='relu',\n",
    "                strides=2,\n",
    "                padding='same')(x)\n",
    "    # elif filters == \"max\":\n",
    "    #     x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    # elif filters == \"average\":\n",
    "    #     x = AveragePooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(latent_dim)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Reshape((4,4,64))(x)\n",
    "for filters in structure:  \n",
    "    if isinstance(filters, int):\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    activation='relu',\n",
    "                    strides=2,\n",
    "                    padding='same')(x)\n",
    "    # elif filters == \"max\" or filters == \"average\":\n",
    "    #             x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "decoded = Conv2DTranspose(filters=3,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='sigmoid',\n",
    "                        padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "ae = Model(x_in, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建为一个独立的模型\n",
    "ae.compile(loss='mean_squared_error',optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 2.3615\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.1462\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.9788\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.8401\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.7199\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6196\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5336\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4645\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3971\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3383\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2868\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2377\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2021\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1625\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.1292\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.0955\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.0664\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.0375\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.0110\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.9814\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.9595\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.9377\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.9133\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.8954\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.8707\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.8571\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.8376\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.8187\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.8049\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7852\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.7755\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.7594\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.7440\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.7360\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.7152\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7102\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.6944\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.6855\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.6721\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.6609\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.6511\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.6420\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.6325\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.6233\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.6142\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.6083\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5993\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5908\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5842\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5773\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5681\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5632\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5556\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5497\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5440\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5386\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5317\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5266\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5202\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.5176\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5094\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.5053\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5001\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4970\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4922\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4886\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 0.4838\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4796\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4764\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4732\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4688\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4671\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4614\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.4589\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4555\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4528\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4497\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4483\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4427\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4415\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4374\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.4346\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4318\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4291\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4252\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4229\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4203\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.4160\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.4143\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.4094\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.4079\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.4043\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.4007\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.3996\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3955\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3927\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3901\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.3868\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3854\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.3808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f40e1e24da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(x_train,x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.save('./AE_models/%s_%s_0.h5'%(id_name,id_model))\n",
    "ae.save_weights('./AE_models/%s_%s_weights_0.h5'%(id_name,id_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.load_weights('./AE_models/%s_%s_weights.h5'%(id_name,id_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    xx = ae.predict(x_test[i].reshape(1,32,32,3), batch_size=batch_size)\n",
    "    # print(xx.shape)\n",
    "    x1 = xx.reshape(32,32,3)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.show()\n",
    "    plt.imshow(x1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(x_1, x_2):\n",
    "    diff = np.abs(x_1 - x_2)\n",
    "    marks = np.mean(np.power(diff, 2), axis=(1,2,3))\n",
    "    return marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_id = []\n",
    "for i in range(len(x_test)):\n",
    "    xx = ae.predict(x_test[i].reshape(1,32,32,3))\n",
    "    score = mark(x_test[i],xx)\n",
    "    # print(score)\n",
    "    sc_id.append(-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_inliners_outliers(inliers, outliers, i_label=1, o_label=0, verbose=False):\n",
    "\n",
    "    temp_outliers = outliers\n",
    "    temp_inliers  = inliers\n",
    "    if i_label==1:\n",
    "        i_labels = np.ones(temp_inliers.shape[0])\n",
    "    else:\n",
    "        i_labels = np.zeros(temp_inliers.shape[0])\n",
    "        \n",
    "    if o_label==0:\n",
    "        o_labels = np.zeros(temp_outliers.shape[0])\n",
    "    else:\n",
    "        o_labels = np.ones(temp_outliers.shape[0])       \n",
    "              \n",
    "    mixed_labels =  np.append(i_labels, o_labels)\n",
    "    mixed_data = np.vstack((temp_inliers, temp_outliers))\n",
    "\n",
    "    return mixed_data, mixed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_inx specifies the index of the OODL found by \"find_oodl\" jupyter file.\n",
    "REM_TOP_LAYER = -2\n",
    "NUM_CLASS = 10\n",
    "if id_name==\"MNIST\" and id_model==\"LeNet\":\n",
    "    layer_inx = 0\n",
    "    OOD_DS_LIST       = OOD_DS_LIST_MNIST\n",
    "    #**********************************************************\n",
    "elif id_name==\"CIFAR10\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_CIFAR10\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 20\n",
    "    #**********************************************************\n",
    "elif id_name==\"SVHN\":\n",
    "    OOD_DS_LIST      = OOD_DS_LIST_SVHN\n",
    "    if id_model==\"VGG\":\n",
    "        layer_inx = 6\n",
    "    elif id_model==\"ResNet\":\n",
    "        layer_inx = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ood_ds_name in enumerate(OOD_DS_LIST):\n",
    "    print(ood_ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_,_),(ood_eva_data,_) = load_dataset('SVHN_CROPPED')\n",
    "das = preprocess_images(id_name, ood_eva_data, id_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(das[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of TINYIMAGENET_RESIZED_32:\n",
      "\n",
      "tnr_at_95_tpr: 88.1699999991183\n",
      "detection_acc: 91.58499999908413\n",
      "AUROC:  96.83788299999999\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of LSUN_RESIZED:\n",
      "\n",
      "tnr_at_95_tpr: 95.7899999990421\n",
      "detection_acc: 95.39499999904604\n",
      "AUROC:  98.959557\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of ISUN_PATCHED:\n",
      "\n",
      "tnr_at_95_tpr: 91.4397759093396\n",
      "detection_acc: 93.2198879541948\n",
      "AUROC:  97.63841344537816\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of SVHN_CROPPED:\n",
      "\n",
      "tnr_at_95_tpr: 0.0076828518745863435\n",
      "detection_acc: 47.50384142546229\n",
      "AUROC:  2.622107790411801\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of G_255:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n",
      "Preprocessing was done for  CIFAR10 VGG\n",
      "The results of U_255:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vriance模块(OODL大类别 --> 删除同样的feature maps)\n",
    "test = np.asarray(sc_id)\n",
    "for i, ood_ds_name in enumerate(OOD_DS_LIST):\n",
    "    (_,_),(ood_eva_data,_) = load_dataset(ood_ds_name)\n",
    "    das = preprocess_images(id_name, ood_eva_data, id_model, verbose=True)\n",
    "    \n",
    "    scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "    \n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        xx = ae.predict(das[i].reshape(1,32,32,3))\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood) \n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "#     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ood_ds_name))\n",
    "#     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "#     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of foolingimages:\n",
      "\n",
      "tnr_at_95_tpr: 99.99999999899998\n",
      "detection_acc: 97.499999999025\n",
      "AUROC:  100.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ood_ds_name = 'foolingimages'\n",
    "\n",
    "das = np.load('adv_datasets/%s_%s_fooling_images.npy'%(id_name,id_model))\n",
    "\n",
    "# scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "# das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "# das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "\n",
    "sc_ood = []\n",
    "for i in range(len(das)):\n",
    "        xx = ae.predict(das[i].reshape(1,32,32,3))\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "\n",
    "ood = np.asarray(sc_ood) \n",
    "scores, mixed_labels = combine_inliners_outliers(test, ood) \n",
    "\n",
    "# print('scores is:', (scores[10000:20000]))\n",
    "fpr, tpr = nums(scores, mixed_labels)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "lens = id_eva_data_processed.shape[0]\n",
    "FP,TN,TP,FN = ErrorRateAt95Recall1(lens,scores, mixed_labels)\n",
    "ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "print('The results of %s:\\n' %(ood_ds_name))\n",
    "# print(get_summary_statistics(scores, mixed_labels))\n",
    "# print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "# print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "print(\"AUROC: \",ROC*100)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9347, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load('./advs_new/%s_%s_normal.npy'%(id_name, id_model),allow_pickle=True)\n",
    "scaler.fit(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test_0 = scaler.transform(x_test.flatten().reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))\n",
    "x_test = x_test_0.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],x_test.shape[3])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_id = []\n",
    "for i in range(len(x_test)):\n",
    "    xx = ae.predict(x_test[i].reshape(1,32,32,3))\n",
    "    score = mark(x_test[i],xx)\n",
    "    # print(score)\n",
    "    sc_id.append(-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of fgsm:\n",
      "\n",
      "tnr_at_95_tpr: 77.12215320822266\n",
      "detection_acc: 86.06107660363632\n",
      "AUROC:  99.97513117427089\n",
      "\n",
      "\n",
      "The results of bim-a:\n",
      "\n",
      "tnr_at_95_tpr: 15.010351966701052\n",
      "detection_acc: 55.00517598287552\n",
      "AUROC:  73.31406856838993\n",
      "\n",
      "\n",
      "The results of bim-b:\n",
      "\n",
      "tnr_at_95_tpr: 23.015873015608282\n",
      "detection_acc: 59.00793650732914\n",
      "AUROC:  84.62939572118616\n",
      "\n",
      "\n",
      "The results of jsma:\n",
      "\n",
      "tnr_at_95_tpr: 17.770876466324236\n",
      "detection_acc: 56.385438232687115\n",
      "AUROC:  76.5697580634223\n",
      "\n",
      "\n",
      "The results of cw-l2:\n",
      "\n",
      "tnr_at_95_tpr: 63.97515527876725\n",
      "detection_acc: 79.48757763890862\n",
      "AUROC:  95.81685565215345\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = np.asarray(sc_id)\n",
    "ADV_DS_LIST = (\"fgsm\", \"bim-a\", \"bim-b\", \"jsma\", \"cw-l2\")\n",
    "for i, ds_name in enumerate(ADV_DS_LIST):\n",
    "    adv = id_name+\"_\"+id_model+\"_\"+ ds_name\n",
    "    das = np.load('./advs_new/'+adv+'.npy',allow_pickle=True)\n",
    "    \n",
    "    scaler.fit(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das_0 = scaler.transform(das.flatten().reshape(das.shape[0],das.shape[1]*das.shape[2]*das.shape[3]))\n",
    "    das = das_0.reshape(das.shape[0],das.shape[1],das.shape[2],das.shape[3])\n",
    "    \n",
    "    sc_ood = []\n",
    "    for i in range(len(das)):\n",
    "        xx = ae.predict(das[i].reshape(1,32,32,3))\n",
    "        score = mark(das[i],xx)\n",
    "        sc_ood.append(-score)\n",
    "    \n",
    "    ood = np.asarray(sc_ood)\n",
    "    scores, mixed_labels = combine_inliners_outliers(test, ood)\n",
    " \n",
    "    fpr, tpr = nums(scores, mixed_labels)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    lens = id_eva_data_processed.shape[0]\n",
    "    FP,TN,TP,FN = ErrorRateAt95Recall1(lens, scores, mixed_labels)\n",
    "    ROC = roc_auc_score(mixed_labels, scores, average='micro', sample_weight=None)\n",
    "    #     print(get_summary_statistics(scores, mixed_labels))\n",
    "    print('The results of %s:\\n' %(ds_name))\n",
    "    #     print('fpr_at_95_tpr:', float(FP) / float(FP + TN+ 1e-7) *100)\n",
    "    print('tnr_at_95_tpr:', float(TN) / float(FP + TN+ 1e-7) *100)\n",
    "    print('detection_acc:',(float(TP) / float(TP + FN + 1e-7)+ float(TN) / float(FP + TN + 1e-7))/2*100)\n",
    "    #     print('detection_errror:',(1.0- float(TP) / float(TP + FN+ 1e-7)+ float(FP) / float(FP + TN+ 1e-7))/2*100)\n",
    "    print(\"AUROC: \",ROC*100)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b5abb0188ba9781ac08b493d925deea1ef4eb1a2330813f3a395ce70cb798d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
